{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f94cea",
   "metadata": {},
   "source": [
    "### This file is to say how to load dOC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e69da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/word_files/intro.docx'}, page_content='Elevator intro pitch\\n\\nfirst of all I would like to thank EY and recruiting team for selecting me for interview process. My name is Yella Reddy, and I’m a Data Scientist with over 3 and half  years of experience applying AI and machine learning across healthcare, insurance, and banking domain.\\n\\nCurrently, I work at Cigna Health, where I build secure, HIPAA-compliant AI solutions. One project I’m especially proud of was developing a GenAI chatbot using LangChain and RAG, we integrated electronic health records of patients by using vector databases like pinecone and deployed through  AWS Bedrock. This gave patients instant, accurate answers about coverage and appointments, reducing call center load.\\n\\nI also automated HIPAA-compliant model deployment using Docker, AWSCodePipeline\\n\\nSo, These experiences taught me how to take AI models all the way from prototype to production \\n\\nEarlier in my career, at Mphasis, I worked with a banking client where I developed a loan default prediction model helping the client reduce financial risk. At HCL Technologies, I focused on demand forecasting, where I built predictive models that improved inventory planning. \\n\\n\\n\\nwhy EY:\\n\\n“I’m excited about EY because it is one of the big four in top financial consulting firms and EY  focusing strongly  on applying AI in their financial services. So  this role give me the chance to work on cutting-edge projects like multi-agent systems and RAG , which directly aligns with my background in building AI chatbots . and I see this role as the perfect opportunity to apply my skills in Python, cloud, and LLMs to make a real impact in financial services.”\\n\\n\\n\\nchallenging project you have faced and how did you overcome it:\\n\\nOne of the challenging projects I faced was at Cigna Health, where we have to deploy the predictive models with the HIPAA compliance protocols. So, the challenge was that the existing system is slow and mostly like the manual. So, apart from it, we should also follow the HIPAA and the federal guidelines becouse patient data should be stored and it should be kept secure. So, to overcome all this, our team designed an automated CI/CD pipeline by using the AWS CodePipeline, Docker, and Kubernetes. So now, when a new model was updated or a new commit was made, then the AWS CodePipeline was automatically triggered and it automatically built the Docker images and the model was tested and deployed to the Kubernetes by protecting the patient data by encryption and deploying in the secure data endpoints.\\n\\n\\n\\n\\n\\nquestions:\\n\\n\\n2. What types of AI/ML projects is the team focusing on right now in financial services. I am asking this because I just want to get an idea in what areas our team is working.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader,UnstructuredWordDocumentLoader\n",
    "\n",
    "doc=Docx2txtLoader(\"data/word_files/intro.docx\")\n",
    "docload=doc.load()\n",
    "docload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5c890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cc3b1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/word_files/intro.docx', 'category_depth': 0, 'emphasized_text_contents': ['Elevator intro pitch'], 'emphasized_text_tags': ['b'], 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'last_modified': '2025-09-15T21:51:21', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText', 'element_id': '09670c3302262812b3527038cb085e56'}, page_content='Elevator intro pitch\\n\\nfirst of all I would like to thank EY and recruiting team for selecting me for interview process. My name is Yella Reddy, and I’m a Data Scientist with over 3 and half  years of experience applying AI and machine learning across healthcare, insurance, and banking domain.'),\n",
       " Document(metadata={'source': 'data/word_files/intro.docx', 'category_depth': 0, 'emphasized_text_contents': ['HIPAA-compliant AI solutions'], 'emphasized_text_tags': ['b'], 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'last_modified': '2025-09-15T21:51:21', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText', 'element_id': '22a436b8faceb5e4cc784f0b055de2a1'}, page_content='Currently, I work at Cigna Health, where I build secure, HIPAA-compliant AI solutions. One project I’m especially proud of was developing a GenAI chatbot using LangChain and RAG, we integrated electronic health records of patients by using vector databases like pinecone and deployed through  AWS Bedrock. This gave patients instant, accurate answers about coverage and appointments, reducing call center load.'),\n",
       " Document(metadata={'source': 'data/word_files/intro.docx', 'category_depth': 0, 'emphasized_text_contents': ['automated HIPAA-compliant model deployment'], 'emphasized_text_tags': ['b'], 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'last_modified': '2025-09-15T21:51:21', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText', 'element_id': '038936b7bd4239c4e13cf8a799a0fd54'}, page_content='I also automated HIPAA-compliant model deployment using Docker, AWSCodePipeline'),\n",
       " Document(metadata={'source': 'data/word_files/intro.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'last_modified': '2025-09-15T21:51:21', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText', 'element_id': 'ae0e6dba90c5f42d95b3ed920d46d396'}, page_content='So, These experiences taught me how to take AI models all the way from prototype to production '),\n",
       " Document(metadata={'source': 'data/word_files/intro.docx', 'category_depth': 0, 'emphasized_text_contents': ['demand forecasting'], 'emphasized_text_tags': ['b'], 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'last_modified': '2025-09-15T21:51:21', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText', 'element_id': '9be9a3d57b8c222d4c606a395f23a3b9'}, page_content='Earlier in my career, at Mphasis, I worked with a banking client where I developed a loan default prediction model helping the client reduce financial risk. At HCL Technologies, I focused on demand forecasting, where I built predictive models that improved inventory planning. '),\n",
       " Document(metadata={'source': 'data/word_files/intro.docx', 'category_depth': 0, 'emphasized_text_contents': ['why EY:'], 'emphasized_text_tags': ['b'], 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'last_modified': '2025-09-15T21:51:21', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText', 'element_id': '8f3c1d40e8bf71de26758cea4b270b92'}, page_content='\\n\\nwhy EY:\\n\\n“I’m excited about EY because it is one of the big four in top financial consulting firms and EY  focusing strongly  on applying AI in their financial services. So  this role give me the chance to work on cutting-edge projects like multi-agent systems and RAG , which directly aligns with my background in building AI chatbots . and I see this role as the perfect opportunity to apply my skills in Python, cloud, and LLMs to make a real impact in financial services.”'),\n",
       " Document(metadata={'source': 'data/word_files/intro.docx', 'category_depth': 0, 'emphasized_text_contents': ['challenging project you have faced and how did you overcome it:'], 'emphasized_text_tags': ['b'], 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'last_modified': '2025-09-15T21:51:21', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText', 'element_id': 'feeed594cfcfeea3ae67eed8a525ed34'}, page_content='challenging project you have faced and how did you overcome it:\\n\\nOne of the challenging projects I faced was at Cigna Health, where we have to deploy the predictive models with the HIPAA compliance protocols. So, the challenge was that the existing system is slow and mostly like the manual. So, apart from it, we should also follow the HIPAA and the federal guidelines becouse patient data should be stored and it should be kept secure. So, to overcome all this, our team designed an automated '),\n",
       " Document(metadata={'source': 'data/word_files/intro.docx', 'languages': ['eng'], 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'PageBreak', 'element_id': 'f18f729accf5047a9c7f99e61dc58260'}, page_content=''),\n",
       " Document(metadata={'source': 'data/word_files/intro.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'last_modified': '2025-09-15T21:51:21', 'page_number': 2, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText', 'element_id': '1b5538e374b4466dc33726423b11c024'}, page_content='CI/CD pipeline by using the AWS CodePipeline, Docker, and Kubernetes. So now, when a new model was updated or a new commit was made, then the AWS CodePipeline was automatically triggered and it automatically built the Docker images and the model was tested and deployed to the Kubernetes by protecting the patient data by encryption and deploying in the secure data endpoints.'),\n",
       " Document(metadata={'source': 'data/word_files/intro.docx', 'category_depth': 0, 'emphasized_text_contents': ['questions:'], 'emphasized_text_tags': ['b'], 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'last_modified': '2025-09-15T21:51:21', 'page_number': 2, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'UncategorizedText', 'element_id': 'ea631ba0231c4da2e743f29ff10a1e28'}, page_content='\\n\\nquestions:\\n'),\n",
       " Document(metadata={'source': 'data/word_files/intro.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'intro.docx', 'last_modified': '2025-09-15T21:51:21', 'page_number': 2, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText', 'element_id': '61e04d921b516c14ca6612321bd16bf0'}, page_content='2. What types of AI/ML projects is the team focusing on right now in financial services. I am asking this because I just want to get an idea in what areas our team is working.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method2 using Unstructured\n",
    "\n",
    "doc2=UnstructuredWordDocumentLoader(\"data/word_files/intro.docx\",mode=\"elements\")\n",
    "docload2=doc2.load()\n",
    "docload2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594c299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
