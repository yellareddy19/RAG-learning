{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4dcf428",
   "metadata": {},
   "source": [
    "### This IPYNB file explains about Hybrid search that is Dense matrix(semantic search) + sparse matrix(exact keyword search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9358b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56b4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=\"LangChain helps build LLM applications.\"),\n",
    "    Document(page_content=\"Pinecone is a vector database for semantic search.\"),\n",
    "    Document(page_content=\"The Eiffel Tower is located in Paris.\"),\n",
    "    Document(page_content=\"Amazon Bedrock allows developers to use multiple foundation models.\"),\n",
    "    Document(page_content=\"FAISS is a fast library for similarity search and clustering.\"),\n",
    "    Document(page_content=\"Retrieval-Augmented Generation improves accuracy by grounding LLMs in external data.\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256f096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dense retriver\n",
    "\n",
    "embedding_model=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "dense_vectorstore=FAISS.from_documents(docs,embedding_model)\n",
    "dense_retriver=dense_vectorstore.as_retriever()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2dc9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sparse retriver\n",
    "\n",
    "sparse_retriver=BM25Retriever.from_documents(docs)\n",
    "sparse_retriver.k=2\n",
    "\n",
    "### combine both retrivers\n",
    "\n",
    "hybrid_retriver=EnsembleRetriever(\n",
    "    retrievers=[dense_retriver,sparse_retriver],\n",
    "    weight=[0.8,0.2]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea894303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001DB42A94050>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x000001DB42A94440>, k=2)], weights=[0.5, 0.5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f0aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"what is Faiss\"\n",
    "\n",
    "result=hybrid_retriver.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0fc145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d8257e2a-8489-4892-a54e-64ee87b6810e', metadata={}, page_content='FAISS is a fast library for similarity search and clustering.'),\n",
       " Document(metadata={}, page_content='Retrieval-Augmented Generation improves accuracy by grounding LLMs in external data.'),\n",
       " Document(id='1a371f96-c11b-4c04-86f6-6caf3d71a6e2', metadata={}, page_content='The Eiffel Tower is located in Paris.'),\n",
       " Document(id='cf85fe13-2d78-4154-b6e6-9ef8398b0eee', metadata={}, page_content='Amazon Bedrock allows developers to use multiple foundation models.'),\n",
       " Document(id='a6b03fe0-9f25-4e88-a95f-3d302646d38a', metadata={}, page_content='LangChain helps build LLM applications.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1418272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###RaG pipeline \n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c68c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate.from_template(\n",
    "    \"\"\"answer the below question on the context what i provided you.\n",
    "    question: {input}\n",
    "    context: {context}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ab4987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()   # Reads the .env file automatically\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b501d856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Retrieval-Augmented Generation is a technology that combines two different types of artificial intelligence: retrieval-based models and generative models. \\n\\nRetrieval-based models search for relevant information or data from a large database or knowledge base and use this information to generate responses. Generative models, on the other hand, generate responses based on a set of rules or patterns without needing to search for external information.\\n\\nWhen these two types of models are combined in Retrieval-Augmented Generation, the system can provide more accurate and relevant responses by both searching for information and generating responses from scratch. This technology is commonly used in chatbots, search engines, and other natural language processing applications to improve the quality of generated content.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 141, 'prompt_tokens': 20, 'total_tokens': 161, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CdTDtQjlxe8e8IWiXSHn8r4lBJVCb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--9d128fe7-056f-43a3-94d8-b76ff974b4e9-0' usage_metadata={'input_tokens': 20, 'output_tokens': 141, 'total_tokens': 161, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=model_name,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "resp = llm.invoke(\"Explain what Retrieval-Augmented Generation is in simple words.\")\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe9ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d71064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
